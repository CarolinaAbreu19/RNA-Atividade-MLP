{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Segunda Questão</h1>\n",
    "\n",
    "<p>O dataset utilizado foi o mesmo disponibilizado na primeira questão.</p>\n",
    "\n",
    "<p>Link: https://www.dropbox.com/s/s2cyx82uxsv03rq/dados-ex5.txt?dl=0</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Leitura do dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados-ex5.txt') \n",
    "print(df.shape)\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definição da coluna alvo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['1.000000000000000000e+00'] \n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Separação do dataset em treino (80%) e teste (20%)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definição do modelo da MLP</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50,50,50,50,50,50), max_iter=100, alpha=1e-4, activation='relu',\n",
    "                    solver='adam', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Projeção da curva de Aprendizado</h3>\n",
    "<p>Relação entre o custo e o número de iterações</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train,y_train)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"Learning rate =\" + str(0.001))\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Projeção da acurácia ao longo das épocas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN_SAMPLES = X_train.shape[0]\n",
    "N_EPOCHS = 60\n",
    "N_BATCH = 128\n",
    "N_CLASSES = np.unique(y_train)\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "epoch = 0\n",
    "\n",
    "while epoch < N_EPOCHS:\n",
    "    print('epoch: ', epoch)\n",
    "    # SHUFFLING\n",
    "    random_perm = np.random.permutation(X_train.shape[0])\n",
    "    mini_batch_index = 0\n",
    "    while True:\n",
    "        # MINI-BATCH\n",
    "        indices = random_perm[mini_batch_index:mini_batch_index + N_BATCH]\n",
    "        mlp.partial_fit(X_train[indices], y_train[indices], classes=N_CLASSES)\n",
    "        mini_batch_index += N_BATCH\n",
    "\n",
    "        if mini_batch_index >= N_TRAIN_SAMPLES:\n",
    "            break\n",
    "            \n",
    "    # SCORE TRAIN\n",
    "    scores_train.append(mlp.score(X_train, y_train))\n",
    "\n",
    "    # SCORE TEST\n",
    "    scores_test.append(mlp.score(X_test, y_test))\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "fig, ax = plt.subplots(2, sharex=True, sharey=True)\n",
    "ax[0].plot(scores_train)\n",
    "ax[0].set_title('Train')\n",
    "ax[1].plot(scores_test)\n",
    "ax[1].set_title('Test')\n",
    "fig.suptitle(\"Accuracy over epochs\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
